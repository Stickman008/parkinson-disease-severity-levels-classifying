{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Dropout, InputLayer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, LearningRateScheduler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler, normalize\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "from my_model import create_model_1, create_model_1_1, create_model_2, create_model_2_1\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Train: 107\n",
      "Length Test: 19\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join('data', 'unionTrain.csv'))\n",
    "test_df = pd.read_csv(os.path.join('data', 'unionTest.csv'))\n",
    "print(f\"Length Train: {len(train_df)}\")\n",
    "print(f\"Length Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_df.drop(['Severity', 'sequence_id'], axis=1), train_df['Severity']\n",
    "X_test, y_test = test_df.drop(['Severity', 'sequence_id'], axis=1), test_df['Severity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:8, Severity:2, [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "idx = 8\n",
    "tm = X_train.iloc[idx][[f'{i}_0X' for i in range(50)]] # max = 854\n",
    "print(f'Index:{idx}, Severity:{y_train[idx]}, {tm.to_list()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_0X</th>\n",
       "      <th>0_0Y</th>\n",
       "      <th>0_1X</th>\n",
       "      <th>0_1Y</th>\n",
       "      <th>0_2X</th>\n",
       "      <th>0_2Y</th>\n",
       "      <th>0_3X</th>\n",
       "      <th>0_3Y</th>\n",
       "      <th>0_4X</th>\n",
       "      <th>0_4Y</th>\n",
       "      <th>...</th>\n",
       "      <th>853_20X</th>\n",
       "      <th>853_20Y</th>\n",
       "      <th>853_21X</th>\n",
       "      <th>853_21Y</th>\n",
       "      <th>853_22X</th>\n",
       "      <th>853_22Y</th>\n",
       "      <th>853_23X</th>\n",
       "      <th>853_23Y</th>\n",
       "      <th>853_24X</th>\n",
       "      <th>853_24Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203.818390</td>\n",
       "      <td>137.074432</td>\n",
       "      <td>213.271698</td>\n",
       "      <td>120.394463</td>\n",
       "      <td>218.456604</td>\n",
       "      <td>128.786789</td>\n",
       "      <td>214.281204</td>\n",
       "      <td>138.171570</td>\n",
       "      <td>209.073471</td>\n",
       "      <td>139.232819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.578170</td>\n",
       "      <td>21.342966</td>\n",
       "      <td>29.684607</td>\n",
       "      <td>82.876892</td>\n",
       "      <td>53.714298</td>\n",
       "      <td>149.624344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>236.188980</td>\n",
       "      <td>71.378502</td>\n",
       "      <td>236.188980</td>\n",
       "      <td>71.378502</td>\n",
       "      <td>236.188980</td>\n",
       "      <td>71.378502</td>\n",
       "      <td>236.188980</td>\n",
       "      <td>71.378502</td>\n",
       "      <td>236.188980</td>\n",
       "      <td>71.378502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>222.626373</td>\n",
       "      <td>125.631256</td>\n",
       "      <td>222.626373</td>\n",
       "      <td>125.631256</td>\n",
       "      <td>222.626373</td>\n",
       "      <td>125.631256</td>\n",
       "      <td>222.626373</td>\n",
       "      <td>125.631256</td>\n",
       "      <td>222.626373</td>\n",
       "      <td>125.631256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126.701424</td>\n",
       "      <td>108.963158</td>\n",
       "      <td>120.373978</td>\n",
       "      <td>85.994064</td>\n",
       "      <td>122.495720</td>\n",
       "      <td>96.498444</td>\n",
       "      <td>129.821487</td>\n",
       "      <td>105.855408</td>\n",
       "      <td>114.185593</td>\n",
       "      <td>106.893127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42700 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0_0X        0_0Y        0_1X        0_1Y        0_2X        0_2Y  \\\n",
       "0  203.818390  137.074432  213.271698  120.394463  218.456604  128.786789   \n",
       "1    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2    0.000000    0.000000    2.578170   21.342966   29.684607   82.876892   \n",
       "3    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "4  126.701424  108.963158  120.373978   85.994064  122.495720   96.498444   \n",
       "\n",
       "         0_3X        0_3Y        0_4X        0_4Y  ...     853_20X  \\\n",
       "0  214.281204  138.171570  209.073471  139.232819  ...    0.000000   \n",
       "1    0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "2   53.714298  149.624344    0.000000    0.000000  ...  236.188980   \n",
       "3    0.000000    0.000000    0.000000    0.000000  ...  222.626373   \n",
       "4  129.821487  105.855408  114.185593  106.893127  ...    0.000000   \n",
       "\n",
       "      853_20Y     853_21X     853_21Y     853_22X     853_22Y     853_23X  \\\n",
       "0    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2   71.378502  236.188980   71.378502  236.188980   71.378502  236.188980   \n",
       "3  125.631256  222.626373  125.631256  222.626373  125.631256  222.626373   \n",
       "4    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "      853_23Y     853_24X     853_24Y  \n",
       "0    0.000000    0.000000    0.000000  \n",
       "1    0.000000    0.000000    0.000000  \n",
       "2   71.378502  236.188980   71.378502  \n",
       "3  125.631256  222.626373  125.631256  \n",
       "4    0.000000    0.000000    0.000000  \n",
       "\n",
       "[5 rows x 42700 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_engineering(df):\n",
    "    return df\n",
    "tmp_X_train = feature_engineering(X_train)\n",
    "tmp_X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaler(scaler_name):\n",
    "    if scaler_name == 'RobustScaler':\n",
    "        scaler = RobustScaler()\n",
    "    elif scaler_name == 'MinMaxScaler':\n",
    "        scaler = MinMaxScaler()\n",
    "    return scaler\n",
    "scaler_name = 'RobustScaler'\n",
    "# scaler_name = 'MinMaxScaler'\n",
    "scaler = get_scaler(scaler_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 488.5626831054688, Min: -5.134825106291681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((107, 854, 50), (19, 854, 50))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(f\"Max: {X_train.max()}, Min: {X_train.min()}\")\n",
    "def modify_X(x):\n",
    "    result = x.copy()\n",
    "    result = result.reshape(-1, 854, 50)\n",
    "    return result\n",
    "X_train_modified = modify_X(X_train)\n",
    "X_test_modified = modify_X(X_test)\n",
    "X_train_modified.shape, X_test_modified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(scaler, os.path.join('saved_scaler', 'MinMaxScaler.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((107, 2), (19, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def modify_y(df):\n",
    "    result = pd.get_dummies(df)\n",
    "    result = result.to_numpy()\n",
    "    return result\n",
    "y_train_modified = modify_y(y_train)\n",
    "y_test_modified = modify_y(y_test)\n",
    "y_train_modified.shape, y_test_modified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 854, 128)          58880     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 854, 64)           41216     \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 25)                1625      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 52        \n",
      "=================================================================\n",
      "Total params: 126,605\n",
      "Trainable params: 126,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape, n_output = (X_train_modified.shape[1], X_train_modified.shape[2]), y_train_modified.shape[1]\n",
    "# model = create_model_1(input_shape, n_output)\n",
    "model = create_model_1_1(input_shape, n_output)\n",
    "# model = create_model_1(input_shape, n_output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=1e-3)\n",
    "model.compile(\n",
    "                optimizer=optimizer,\n",
    "                loss=CategoricalCrossentropy(),\n",
    "                metrics=[\n",
    "                    'accuracy'\n",
    "                ]\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(\n",
    "                                monitor='val_loss',\n",
    "                                factor=0.5,\n",
    "                                patience=4,\n",
    "                                min_lr=1e-4\n",
    "                              )\n",
    "early_stopping = EarlyStopping(\n",
    "                                monitor='loss',\n",
    "                                patience=6\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 [==============================] - 25s 3s/step - loss: 0.6403 - accuracy: 0.5647 - val_loss: 0.6430 - val_accuracy: 0.6364\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.5008 - accuracy: 0.7412 - val_loss: 0.7345 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.4611 - accuracy: 0.7647 - val_loss: 0.7198 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.4222 - accuracy: 0.7647 - val_loss: 0.6678 - val_accuracy: 0.5909\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.3924 - accuracy: 0.7765 - val_loss: 0.7502 - val_accuracy: 0.5909\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.3583 - accuracy: 0.8118 - val_loss: 0.7883 - val_accuracy: 0.5909\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.3443 - accuracy: 0.8353 - val_loss: 0.7939 - val_accuracy: 0.5909\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.3276 - accuracy: 0.8471 - val_loss: 0.8069 - val_accuracy: 0.6818\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.3150 - accuracy: 0.8235 - val_loss: 0.8179 - val_accuracy: 0.6364\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.2993 - accuracy: 0.8706 - val_loss: 0.7966 - val_accuracy: 0.5909\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2894 - accuracy: 0.8706 - val_loss: 0.7969 - val_accuracy: 0.5909\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.2781 - accuracy: 0.8706 - val_loss: 0.7977 - val_accuracy: 0.6364\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.2679 - accuracy: 0.8706 - val_loss: 0.7948 - val_accuracy: 0.6364\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.2566 - accuracy: 0.8824 - val_loss: 0.7791 - val_accuracy: 0.6818\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.2498 - accuracy: 0.8941 - val_loss: 0.7704 - val_accuracy: 0.6818\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.2427 - accuracy: 0.9059 - val_loss: 0.7804 - val_accuracy: 0.6818\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.2344 - accuracy: 0.9176 - val_loss: 0.7882 - val_accuracy: 0.7273\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.2274 - accuracy: 0.9294 - val_loss: 0.7862 - val_accuracy: 0.7273\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.2207 - accuracy: 0.9412 - val_loss: 0.7764 - val_accuracy: 0.7273\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2132 - accuracy: 0.9529 - val_loss: 0.7771 - val_accuracy: 0.7273\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2067 - accuracy: 0.9529 - val_loss: 0.7853 - val_accuracy: 0.7273\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.1992 - accuracy: 0.9529 - val_loss: 0.7885 - val_accuracy: 0.6818\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.1902 - accuracy: 0.9529 - val_loss: 0.7964 - val_accuracy: 0.6818\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.1831 - accuracy: 0.9529 - val_loss: 0.7946 - val_accuracy: 0.6818\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.1764 - accuracy: 0.9412 - val_loss: 0.7965 - val_accuracy: 0.7273\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.1692 - accuracy: 0.9529 - val_loss: 0.7918 - val_accuracy: 0.6818\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.1599 - accuracy: 0.9529 - val_loss: 0.7767 - val_accuracy: 0.6818\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.1522 - accuracy: 0.9647 - val_loss: 0.7813 - val_accuracy: 0.6818\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.1455 - accuracy: 0.9647 - val_loss: 0.7838 - val_accuracy: 0.6818\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.1388 - accuracy: 0.9647 - val_loss: 0.7874 - val_accuracy: 0.6818\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.1319 - accuracy: 0.9529 - val_loss: 0.8083 - val_accuracy: 0.6818\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.1225 - accuracy: 0.9529 - val_loss: 0.8151 - val_accuracy: 0.6818\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.1157 - accuracy: 0.9765 - val_loss: 0.7874 - val_accuracy: 0.6818\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.1086 - accuracy: 0.9882 - val_loss: 0.7738 - val_accuracy: 0.6818\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.1001 - accuracy: 0.9765 - val_loss: 0.7859 - val_accuracy: 0.6818\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.0967 - accuracy: 0.9647 - val_loss: 0.7967 - val_accuracy: 0.6818\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.0902 - accuracy: 0.9882 - val_loss: 0.7871 - val_accuracy: 0.6818\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.0985 - accuracy: 0.9647 - val_loss: 0.8214 - val_accuracy: 0.6818\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.0765 - accuracy: 0.9882 - val_loss: 0.7819 - val_accuracy: 0.6818\n",
      "Epoch 40/200\n",
      "2/3 [===================>..........] - ETA: 1s - loss: 0.0794 - accuracy: 0.9688"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_modified, y_train_modified,\n",
    "          batch_size=32,\n",
    "          epochs=200,\n",
    "          shuffle=True,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[\n",
    "              reduce_lr,\n",
    "              early_stopping,\n",
    "              ]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "# model.save(os.path.join(\"saved_models\", f\"trained_at_{current_time}_using_{scaler_name}.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validate'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = model.predict(X_train_modified)\n",
    "train_real_predict = np.argmax(train_predict, axis=1)+1\n",
    "for i in range(len(y_train)):\n",
    "    print(f\"Index:{i}, Predict:{train_real_predict[i]}, Real:{y_train[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_train = f1_score(y_train, train_real_predict)\n",
    "accuracy_train = accuracy_score(y_train, train_real_predict)\n",
    "# print(f\"f1: {f1_train}\\naccuracy: {accuracy_train}\")\n",
    "print(classification_report(y_train, train_real_predict))\n",
    "print(\"---------------------------------------------------------\")\n",
    "sns.heatmap(confusion_matrix(y_train, train_real_predict),annot = True,fmt = '2.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = model.predict(X_test_modified)\n",
    "test_real_predict = np.argmax(test_predict, axis=1)+1\n",
    "for i in range(len(y_test)):\n",
    "    print(f\"Index:{i}, Predict:{test_real_predict[i]}, Real:{y_test[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_test = f1_score(y_test, test_real_predict)\n",
    "accuracy_test = accuracy_score(y_test, test_real_predict)\n",
    "print(f\"f1: {f1_test}\\naccuracy: {accuracy_test}\")\n",
    "print(classification_report(y_test, test_real_predict))\n",
    "print(\"---------------------------------------------------------\")\n",
    "sns.heatmap(confusion_matrix(y_test, test_real_predict),annot = True,fmt = '2.0f')\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf2-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "586ea256996c4d1afba0a24bd3ac38219670b30d200ba45ddfed159cb38a21bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
