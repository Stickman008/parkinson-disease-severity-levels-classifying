{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Dropout, InputLayer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, LearningRateScheduler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler, normalize\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "from my_model import create_model_1, create_model_1_1, create_model_1_2, create_model_2, create_model_2_1\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join('data', 'unionTrain.csv'))\n",
    "test_df = pd.read_csv(os.path.join('data', 'unionTest.csv'))\n",
    "print(f\"Length Train: {len(train_df)}\")\n",
    "print(f\"Length Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_df.drop(['Severity', 'sequence_id'], axis=1), train_df['Severity']\n",
    "X_test, y_test = test_df.drop(['Severity', 'sequence_id'], axis=1), test_df['Severity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 8\n",
    "tm = X_train.iloc[idx][[f'{i}_0X' for i in range(50)]] # max = 854\n",
    "print(f'Index:{idx}, Severity:{y_train[idx]}, {tm.to_list()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    result = df.copy()\n",
    "    # tmp = pd.DataFrame()\n",
    "    # for i in range(50):\n",
    "    #     result\n",
    "    return result\n",
    "tmp_X_train = feature_engineering(X_train)\n",
    "tmp_X_test = feature_engineering(X_test)\n",
    "tmp_X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaler(scaler_name):\n",
    "    if scaler_name == 'RobustScaler':\n",
    "        scaler = RobustScaler()\n",
    "    elif scaler_name == 'MinMaxScaler':\n",
    "        scaler = MinMaxScaler()\n",
    "    return scaler\n",
    "scaler_name = 'RobustScaler'\n",
    "# scaler_name = 'MinMaxScaler'\n",
    "scaler = get_scaler(scaler_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(f\"Max: {X_train.max()}, Min: {X_train.min()}\")\n",
    "def modify_X(x):\n",
    "    result = x.copy()\n",
    "    result = result.reshape(-1, 854, 50)\n",
    "    return result\n",
    "X_train_modified = modify_X(X_train)\n",
    "X_test_modified = modify_X(X_test)\n",
    "X_train_modified.shape, X_test_modified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(scaler, os.path.join('saved_scaler', 'MinMaxScaler.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_y(df):\n",
    "    result = pd.get_dummies(df)\n",
    "    result = result.to_numpy()\n",
    "    return result\n",
    "y_train_modified = modify_y(y_train)\n",
    "y_test_modified = modify_y(y_test)\n",
    "y_train_modified.shape, y_test_modified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape, n_output = (X_train_modified.shape[1], X_train_modified.shape[2]), y_train_modified.shape[1]\n",
    "# model = create_model_1(input_shape, n_output)\n",
    "# model = create_model_1_1(input_shape, n_output)\n",
    "model = create_model_1_2(input_shape, n_output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=1e-3)\n",
    "model.compile(\n",
    "                optimizer=optimizer,\n",
    "                loss=CategoricalCrossentropy(),\n",
    "                metrics=[\n",
    "                    'accuracy'\n",
    "                ]\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(\n",
    "                                monitor='val_loss',\n",
    "                                factor=0.5,\n",
    "                                patience=4,\n",
    "                                min_lr=1e-4\n",
    "                              )\n",
    "early_stopping = EarlyStopping(\n",
    "                                monitor='loss',\n",
    "                                patience=6\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_modified, y_train_modified,\n",
    "          batch_size=32,\n",
    "          epochs=30,\n",
    "          shuffle=True,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[\n",
    "              reduce_lr,\n",
    "              early_stopping,\n",
    "              ]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "# model.save(os.path.join(\"saved_models\", f\"trained_at_{current_time}_using_{scaler_name}.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validate'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = model.predict(X_train_modified)\n",
    "train_real_predict = np.argmax(train_predict, axis=1)+1\n",
    "for i in range(len(y_train)):\n",
    "    print(f\"Index:{i}, Predict:{train_real_predict[i]}, Real:{y_train[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_train = f1_score(y_train, train_real_predict)\n",
    "accuracy_train = accuracy_score(y_train, train_real_predict)\n",
    "# print(f\"f1: {f1_train}\\naccuracy: {accuracy_train}\")\n",
    "print(classification_report(y_train, train_real_predict))\n",
    "print(\"---------------------------------------------------------\")\n",
    "sns.heatmap(confusion_matrix(y_train, train_real_predict),annot = True,fmt = '2.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = model.predict(X_test_modified)\n",
    "test_real_predict = np.argmax(test_predict, axis=1)+1\n",
    "for i in range(len(y_test)):\n",
    "    print(f\"Index:{i}, Predict:{test_real_predict[i]}, Real:{y_test[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_test = f1_score(y_test, test_real_predict)\n",
    "accuracy_test = accuracy_score(y_test, test_real_predict)\n",
    "print(f\"f1: {f1_test}\\naccuracy: {accuracy_test}\")\n",
    "print(classification_report(y_test, test_real_predict))\n",
    "print(\"---------------------------------------------------------\")\n",
    "sns.heatmap(confusion_matrix(y_test, test_real_predict),annot = True,fmt = '2.0f')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf2-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "586ea256996c4d1afba0a24bd3ac38219670b30d200ba45ddfed159cb38a21bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
