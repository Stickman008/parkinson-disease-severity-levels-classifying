{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler, normalize\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "from utils import mod_df, drop_features, inverse_mod_X, inverse_mod_y, apply_savgol_filter, apply_median_filter, apply_maximum_filter, apply_is_zero\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join('data', 'unionTrain.csv'))\n",
    "test_df = pd.read_csv(os.path.join('data', 'unionTest.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = mod_df(train_df)\n",
    "X_test, y_test = mod_df(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    result = df.copy()\n",
    "    \n",
    "    # drop features\n",
    "    result = result.drop(['id', 'timestep'], axis=1)\n",
    "    DEFAULT_FEATURE = result.columns.to_list()\n",
    "    # result = drop_features(result,[0,1,2,5,15,16,17,18,21,20,23,24])\n",
    "    # result = drop_features(result, [15, 16, 17, 18, 20, 21, 23, 24])\n",
    "    \n",
    "    # add features\n",
    "    FEATURE_COLUMNS = result.columns.to_list()\n",
    "    for col in tqdm(FEATURE_COLUMNS):\n",
    "        feature = result[col]\n",
    "        feature = feature.to_numpy()\n",
    "        result[f'{col}_savgol'] = apply_savgol_filter(feature, window_size=11, polynomial=2)\n",
    "        result[f'{col}_median'] = apply_median_filter(feature)\n",
    "        # result[f'{col}_max'] = apply_maximum_filter(feature)\n",
    "        result[f'{col}_sav_med'] = apply_median_filter(apply_savgol_filter(feature, window_size=21), window_size=5)\n",
    "        result[f'{col}_is_zero'] = apply_is_zero(feature)\n",
    "    \n",
    "    # modify features\n",
    "    FEATURE_COLUMNS = result.columns.to_list()\n",
    "    for col in tqdm(FEATURE_COLUMNS):\n",
    "        feature = result[col]\n",
    "        feature = feature.to_numpy()\n",
    "        # result[col] = apply_savgol_filter(feature)\n",
    "        # result[col] = apply_median_filter(feature)\n",
    "        # result[col] = apply_median_filter(apply_savgol_filter(feature, window_size=21), window_size=5)\n",
    "    \n",
    "    # drop default features\n",
    "    # result = result.drop(DEFAULT_FEATURE, axis=1)\n",
    "      \n",
    "    return result\n",
    "\n",
    "X_train_1 = feature_engineering(X_train)\n",
    "X_test_1 = feature_engineering(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler_name = 'RobustScaler.pkl'\n",
    "# scaler_name = 'MinMaxScaler.pkl'\n",
    "scaler_name = 'MinMaxScaler_wo_max.pkl'\n",
    "scaler = joblib.load(os.path.join('saved_scaler', scaler_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.transform(X_train_1)\n",
    "X_test_scaled = scaler.transform(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_modified, y_train_modified = inverse_mod_X(X_train_scaled), inverse_mod_y(y_train)\n",
    "X_test_modified, y_test_modified = inverse_mod_X(X_test_scaled), inverse_mod_y(y_test)\n",
    "print(X_train_modified.shape, y_train_modified.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '2022-11-11_18-57-17_MinMaxScaler_15.h5'\n",
    "model = load_model(os.path.join('saved_models', model_name))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = model.predict(X_train_modified)\n",
    "train_predict = np.argmax(train_predict, axis=1)+1\n",
    "train_real = np.argmax(y_train_modified, axis=1)+1\n",
    "\n",
    "# for i in range(len(y_train_modified)):\n",
    "#     print(f\"Index:{i}, Predict:{train_predict[i]}, Real:{train_real[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_train = f1_score(train_real, train_predict)\n",
    "accuracy_train = accuracy_score(train_real, train_predict)\n",
    "# print(f\"f1: {f1_train:.4f}\\naccuracy: {accuracy_train:.4f}\")\n",
    "print(classification_report(train_real, train_predict, digits=4))\n",
    "print(\"---------------------------------------------------------\")\n",
    "sns.heatmap(confusion_matrix(train_real, train_predict),annot = True,fmt = '2.0f')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = model.predict(X_test_modified)\n",
    "test_predict = np.argmax(test_predict, axis=1)+1\n",
    "test_real = np.argmax(y_test_modified, axis=1)+1\n",
    "\n",
    "# for i in range(len(y_test)):\n",
    "#     print(f\"Index:{i}, Predict:{test_real[i]}, Real:{test_real[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_test = f1_score(test_real, test_predict)\n",
    "accuracy_test = accuracy_score(test_real, test_predict)\n",
    "# print(f\"f1: {f1_test:.4f}\\naccuracy: {accuracy_test:.4f}\")\n",
    "print(classification_report(test_real, test_predict, digits=4))\n",
    "print(\"---------------------------------------------------------\")\n",
    "sns.heatmap(confusion_matrix(test_real, test_predict),annot = True,fmt = '2.0f')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf2-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "586ea256996c4d1afba0a24bd3ac38219670b30d200ba45ddfed159cb38a21bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
