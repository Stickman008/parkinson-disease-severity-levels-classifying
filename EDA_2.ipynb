{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler, normalize\n",
    "\n",
    "from utils.data_utils import mod_df, drop_features, inverse_mod_X, inverse_mod_y, fill_with_mean, apply_standard_scale, apply_std, apply_is_zero\n",
    "# from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join('data', 'unionTrain.csv'))\n",
    "test_df = pd.read_csv(os.path.join('data', 'unionTest.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = mod_df(train_df)\n",
    "X_test, y_test = mod_df(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    result = df.copy()\n",
    "    \n",
    "    # select & drop features\n",
    "    result = result.drop(['id', 'timestep'], axis=1)\n",
    "    # result = drop_features(result,[0,1,2,5,15,16,17,18,21,20,23,24])\n",
    "    # result = drop_features(result, [15, 16, 17, 18, 20, 21, 23, 24])\n",
    "    # result = result[['0X', '1Y', '4Y', '5Y', '7X', '8Y', '12Y', '13Y', '14Y', '17Y', '20X', '24X', '24Y']] # ts = 0.09\n",
    "    # result = result[['1Y','2Y','4Y','5Y','6Y','7X','8Y','11Y','12Y','13Y','14Y','20X','22Y','23X','24X','24Y']] # ts = 0.07 bug\n",
    "    # result = result[['1Y', '2Y', '4X', '4Y', '5Y', '6Y', '7X', '8Y', '10X', '11Y', '12Y', '13Y', '14X', '14Y', '20X', '21Y', '22Y', '23X', '24X', '24Y']] # ts = 0.04 bug\n",
    "    # result = result[['1Y', '2Y', '3Y', '4X', '4Y', '5Y', '6Y', '7X', '7Y', '8Y', '10X', '11Y', '12X', '12Y', '13Y', '14X', '14Y', '16Y', '20X', '21Y', '22X', '22Y', '23X', '23Y', '24X', '24Y']] # ts = 0.001 bug\n",
    "    DEFAULT_FEATURE = result.columns.to_list()\n",
    "    \n",
    "    # fill outlier\n",
    "    # for col in tqdm(DEFAULT_FEATURE):\n",
    "    #     feature = result[col].to_numpy()\n",
    "    #     result[col] = fill_with_mean(feature)\n",
    "    \n",
    "    # add features\n",
    "    # result['test_0X'] = result['0X']\n",
    "    FEATURE_COLUMNS = result.columns.to_list()\n",
    "    for col in tqdm(FEATURE_COLUMNS):\n",
    "        feature = result[col]\n",
    "        feature = feature.to_numpy()\n",
    "        # result[f'{col}_savgol_1'] = apply_savgol_filter(feature, window_size=21, polynomial=1)\n",
    "        # result[f'{col}_savgol_7'] = apply_savgol_filter(feature, window_size=21, polynomial=2)\n",
    "        # result[f'{col}_savgol_2'] = apply_savgol_filter(feature, window_size=21, polynomial=3)\n",
    "        # result[f'{col}_savgol_3'] = apply_savgol_filter(feature, window_size=21, polynomial=5)\n",
    "        # result[f'{col}_savgol_4'] = apply_savgol_filter(feature, window_size=11, polynomial=1)\n",
    "        # result[f'{col}_savgol_8'] = apply_savgol_filter(feature, window_size=11, polynomial=2)\n",
    "        # result[f'{col}_savgol_5'] = apply_savgol_filter(feature, window_size=11, polynomial=3)\n",
    "        # result[f'{col}_savgol_6'] = apply_savgol_filter(feature, window_size=11, polynomial=5)\n",
    "        # result[f'{col}_median'] = apply_median_filter(feature)\n",
    "        # result[f'{col}_max'] = apply_maximum_filter(feature, window_size=5)\n",
    "        # result[f'{col}_sav_med'] = apply_median_filter(apply_savgol_filter(feature, window_size=21), window_size=5)\n",
    "        # result[f'{col}_sav_min_max_scale'] = apply_min_max_scale(apply_savgol_filter(feature, window_size=11, polynomial=2))\n",
    "        # result[f'{col}_standard_min_max_scale'] = apply_min_max_scale(apply_standard_scale(feature))\n",
    "        \n",
    "\n",
    "        # result[f'{col}_max'] = apply_max_value(feature)\n",
    "        # result[f'{col}_min'] = apply_min_value(feature)\n",
    "        # result[f'{col}_mean'] = apply_mean(feature)\n",
    "        # result[f'{col}_std'] = apply_std(feature)\n",
    "        # result[f'{col}_is_zero'] = apply_is_zero(feature)\n",
    "        # result[f'{col}_min_max_scale'] = apply_min_max_scale(feature)\n",
    "        result[f'{col}_standard_scale'] = apply_standard_scale(feature)\n",
    "        # result[f'{col}_fill_with_mean'] = fill_with_mean(feature)\n",
    "    \n",
    "    # modify features\n",
    "    FEATURE_COLUMNS = result.columns.to_list()\n",
    "    for col in tqdm(FEATURE_COLUMNS):\n",
    "        feature = result[col]\n",
    "        feature = feature.to_numpy()\n",
    "        # result[col] = apply_savgol_filter(feature)\n",
    "        # result[col] = apply_median_filter(feature)\n",
    "        # result[col] = apply_median_filter(apply_savgol_filter(feature, window_size=21), window_size=5)\n",
    "        # result[col] = fill_with_mean(feature)\n",
    "        # result[col] = apply_standard_scale(feature)\n",
    "    \n",
    "    # drop default features\n",
    "    # result = result.drop(DEFAULT_FEATURE, axis=1)\n",
    "      \n",
    "    return result\n",
    "\n",
    "X_train_1 = feature_engineering(X_train)\n",
    "X_test_1 = feature_engineering(X_test)\n",
    "y_train_1 = np.argmax(y_train.to_numpy(), axis=1)+1\n",
    "y_test_1 = np.argmax(y_test.to_numpy(), axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_1['0X'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1['0X'].to_numpy().shape\n",
    "DEFAULT_FEATURE = X_train_1.columns.to_list()\n",
    "# y_train_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_hist(pd_series, bins=100, feature_name=None, range=None):\n",
    "    plt.hist(pd_series, bins=bins, range=range)\n",
    "    plt.axvline(pd_series.mean(), color='red')\n",
    "    plt.axvline(pd_series.mean()-pd_series.std(), color='blue')\n",
    "    plt.axvline(pd_series.mean()+pd_series.std(), color='blue')\n",
    "    plt.axvline(pd_series.mean()-2*pd_series.std(), color='green')\n",
    "    plt.axvline(pd_series.mean()+2*pd_series.std(), color='green')\n",
    "    plt.title(feature_name)\n",
    "    plt.grid()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist = X_train_1[X_train_1_feature>10].hist(feature, bins=100)\n",
    "feature = '1Y'\n",
    "X_train_1_feature = X_train_1[feature]\n",
    "X_train_1_feature_mod = X_train_1_feature\n",
    "# X_train_1_feature_mod = X_train_1_feature[X_train_1_feature>0]\n",
    "plot_feature_hist(X_train_1_feature_mod, bins=100, feature_name=feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in ['4X', '4Y', '5X', '5Y', '6X', '6Y', '8X', '8Y', '9X', '9Y']:\n",
    "    X_train_1_feature = X_train_1[feature]\n",
    "    X_train_1_feature_mod = X_train_1_feature\n",
    "    # X_train_1_feature_mod = X_train_1_feature[X_train_1_feature>0]\n",
    "    # X_train_1_feature_mod.hist()\n",
    "    # plot_feature_hist(X_train_1_feature_mod, bins=100, feature_name=feature, range=None)\n",
    "    # plot_feature_hist(X_train_1[f'{feature}_fill_with_mean'], bins=100, feature_name=feature, range=None)\n",
    "    # plot_feature_hist(X_train_1[f'{feature}_standard_scale'], bins=100, feature_name=feature, range=None)\n",
    "    plot_feature_hist(X_train_1[f\"{feature}_standard_scale\"], bins=100, feature_name=feature, range=(-8, 8))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('py3_10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "dae23cc1304adc3b3cd65b9387d8b9dd19248d8974b41ba28d07249eeed262aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
