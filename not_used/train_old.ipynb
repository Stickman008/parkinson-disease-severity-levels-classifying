{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Dropout, InputLayer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, LearningRateScheduler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler, normalize\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "from my_model import create_model_1, create_model_1_1, create_model_1_2, create_model_2, create_model_2_1\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join('data', 'unionTrain.csv'))\n",
    "test_df = pd.read_csv(os.path.join('data', 'unionTest.csv'))\n",
    "print(f\"Length Train: {len(train_df)}\")\n",
    "print(f\"Length Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_df.drop(['Severity', 'sequence_id'], axis=1), train_df['Severity']\n",
    "X_test, y_test = test_df.drop(['Severity', 'sequence_id'], axis=1), test_df['Severity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 8\n",
    "tm = X_train.iloc[idx][[f'{i}_0X' for i in range(50)]] # max = 854\n",
    "print(f'Index:{idx}, Severity:{y_train[idx]}, {tm.to_list()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    result = df.copy()\n",
    "    # tmp = pd.DataFrame()\n",
    "    # for i in range(50):\n",
    "    #     result\n",
    "    return result\n",
    "tmp_X_train = feature_engineering(X_train)\n",
    "tmp_X_test = feature_engineering(X_test)\n",
    "tmp_X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaler(scaler_name):\n",
    "    if scaler_name == 'RobustScaler':\n",
    "        scaler = RobustScaler()\n",
    "    elif scaler_name == 'MinMaxScaler':\n",
    "        scaler = MinMaxScaler()\n",
    "    return scaler\n",
    "# scaler_name = 'RobustScaler'\n",
    "scaler_name = 'MinMaxScaler'\n",
    "scaler = get_scaler(scaler_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(f\"Max: {X_train.max()}, Min: {X_train.min()}\")\n",
    "def modify_X(x):\n",
    "    result = x.copy()\n",
    "    result = result.reshape(-1, 854, 50)\n",
    "    return result\n",
    "X_train_modified = modify_X(X_train)\n",
    "X_test_modified = modify_X(X_test)\n",
    "X_train_modified.shape, X_test_modified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(scaler, os.path.join('saved_scaler', 'MinMaxScaler.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_y(df):\n",
    "    result = pd.get_dummies(df)\n",
    "    result = result.to_numpy()\n",
    "    return result\n",
    "y_train_modified = modify_y(y_train)\n",
    "y_test_modified = modify_y(y_test)\n",
    "y_train_modified.shape, y_test_modified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape, n_output = (X_train_modified.shape[1], X_train_modified.shape[2]), y_train_modified.shape[1]\n",
    "model = create_model_1(input_shape, n_output)\n",
    "# model = create_model_1_1(input_shape, n_output)\n"]
   },
